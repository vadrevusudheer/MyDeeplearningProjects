# Step 1: Installation and Setup

# Installing TensorFlow
! pip install -q tensorflow-gpu

import tensorflow as tf
print(tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Step 2: Data Preprocessing

# Importing the dataset
from tensorflow.keras.datasets import cifar10

# Loading the dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

class_names = ['0: airplane', '1: automobile', '2: bird', '3: cat', '4: deer', '5: dog', '6: frog', '7: horse', '8: ship', '9: truck']

print(class_names)

x_train.max(), x_train.min(), x_train.mean()

y_train.max(), y_train.min()

class_names

# Normalizing the images
x_train = x_train / 255.0
x_test = x_test / 255.0

x_train.max(), x_train.min(), x_train.mean()

x_train.shape, x_test.shape

plt.imshow(x_train[0])

y_train[0]

class_names

# Step 3: Building the CNN

# Defining the object
model = tf.keras.models.Sequential()


# Adding first CCN layer
# 1) filters (kernel) = 32
# 2) kernal size = 3
# 3) padding = same
# 4) activation = ReLU
# 5) input shape = (32, 32, 3)

model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape = [32, 32, 3]))

# Adding second CNN layer and maxpool layer
# 1) filters (kernel) = 32
# 2) kernal size = 3
# 3) padding = same
# 4) activation = ReLU

model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))

# maxpool layer parameters,
# 1) pool size = 2
# 2) strides = 2
# 3) padding = valid

model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

# Adding third CNN layer
# 1) filters (kernel) = 64
# 2) kernal size = 3
# 3) padding = same
# 4) activation = ReLU

model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))

# Adding fourth CNN layer and maxpool layer
# 1) filters (kernel) = 64
# 2) kernal size = 3
# 3) padding = same
# 4) activation = ReLU

model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))

# maxpool layer parameters,
# 1) pool size = 2
# 2) strides = 2
# 3) padding = valid

model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))

# Adding the dropout layer
model.add(tf.keras.layers.Dropout(0.4))

# Adding the Flattening layer
model.add(tf.keras.layers.Flatten())

# Adding first dense layer
model.add(tf.keras.layers.Dense(units=128, activation='relu'))

# Adding second dense layer (output layer)
model.add(tf.keras.layers.Dense(units=10, activation='softmax'))

model.summary()

# Step 4: Training the model

# Compiling the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])


model.fit(x_train, y_train, batch_size=10, epochs=10)

# Step 5: Model evaluation and prediction

# evaluate the model performane
test_loss, test_acc = model.evaluate(x_test, y_test)

print('Test Accuracy is: {}'.format(test_acc))

# Predictions
y_pred = model.predict_classes(x_test)

print(y_pred[0]), print(y_test[0])

# Confusion matrix

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)

acc_cm = accuracy_score(y_test, y_pred)
print(acc_cm)
