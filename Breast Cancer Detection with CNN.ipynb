# Step 1: Installation and Setup

# Installing TensorFlow
! pip install -q tensorflow-gpu

import tensorflow as tf

print(tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Step 2: Data Preprocessing

from sklearn import datasets, metrics

# import the dataset
cancer = datasets.load_breast_cancer()

print(cancer.DESCR)

# matrix of features
x = pd.DataFrame(data = cancer.data, columns=cancer.feature_names)

x.head()

# dependent variable
y = cancer.target
print(y)

cancer.target_names

x.shape, y.shape

# splitting the dataset in train and test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)

x_train.shape, x_test.shape

# feature scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_train.shape, x_test.shape

x_train = x_train.reshape(455, 30, 1)
x_test = x_test.reshape(114, 30, 1)


x_train.shape, x_test.shape

# Step 3: Building the model

# define an object
model = tf.keras.models.Sequential()

# First CNN layer
model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu', input_shape = (30, 1)))

# batch normalization
model.add(tf.keras.layers.BatchNormalization())

# dropout layer
model.add(tf.keras.layers.Dropout(0.2))

# second CNN layer
model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu'))

# batch normalization
model.add(tf.keras.layers.BatchNormalization())

# dropout layer
model.add(tf.keras.layers.Dropout(0.4))

# flatten layer
model.add(tf.keras.layers.Flatten())

# dense layer
model.add(tf.keras.layers.Dense(units=64, activation='relu'))

# output layer
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))


model.summary()

# compile model

opt = tf.keras.optimizers.Adam(learning_rate=0.00005)

model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Step 4: Training the model

history =  model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))

# Step 5: Model Prediction

y_pred = model.predict_classes(x_test)

print(y_pred[12]), print(y_test[12])

cancer.target_names

# confusion matrix
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)

acc_cm = accuracy_score(y_test, y_pred)
print(acc_cm)

# Stpe 6: Learning curve

def learning_curve(history, epoch):

  # training vs validation accuracy
  epoch_range = range(1, epoch+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.title('Model Accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'val'], loc='upper left')
  plt.show()

  # training vs validation loss
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.title('Model Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'val'], loc='upper left')
  plt.show()

learning_curve(history, 50)
